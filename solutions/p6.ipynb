{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DMG2 Assignment : Problem 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Naive Bayes Text Classifier_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of classes : 20\n",
    "\n",
    "In each class, there are a number of documents, each one corresponding to a date. The test-train split will be based on the date. \n",
    "\n",
    "**Preprocessing in each document :**\n",
    "* Keep only From, Subject, Host, Organization, Data\n",
    "* Remove special characters, stop words\n",
    "* Stem the words\n",
    "* There are numbers in the data, as addresses, phone numbers, currency, etc. Should they be removed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk,unicodedata\n",
    "import operator,math\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/jishnu/Documents/ISB/Term3/dmg2/assignments/hw_assignment1/dmg2/datasets/20_newsgroups'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels,files_list = [],[]\n",
    "for root, dirs, files in os.walk(DATA_DIR):\n",
    "    for file in files:\n",
    "        labels.append(re.sub(r'/home/jishnu/Documents/ISB/Term3/dmg2/assignments/hw_assignment1/dmg2/datasets/20_newsgroups/','',root))\n",
    "        files_list.append(os.path.join(root,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comp.graphics',\n",
       " 'talk.religion.misc',\n",
       " 'rec.sport.baseball',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'rec.motorcycles',\n",
       " 'talk.politics.guns',\n",
       " 'misc.forsale',\n",
       " 'alt.atheism',\n",
       " 'talk.politics.misc',\n",
       " 'talk.politics.mideast',\n",
       " 'rec.autos',\n",
       " 'comp.windows.x',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'soc.religion.christian',\n",
       " 'rec.sport.hockey',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'sci.space',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'sci.med']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_df = pd.DataFrame({'filename':files_list, 'label' : labels})\n",
    "list(files_df['label'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each class, splitting the documents to training and test based on a 70-30 rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13997 6000\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame(columns=['filename','label'])\n",
    "test = pd.DataFrame(columns=['filename','label'])\n",
    "\n",
    "for label in list(files_df['label'].unique()):\n",
    "    threshold = files_df.loc[files_df['label'] == label].shape[0] * 0.7\n",
    "    threshold = int(np.floor(threshold))\n",
    "    train = train.append(files_df.loc[files_df['label'] == label].iloc[:threshold,:],ignore_index=True)\n",
    "    test = test.append(files_df.loc[files_df['label'] == label].iloc[threshold:,:],ignore_index=True)\n",
    "\n",
    "print(train.shape[0],test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dictionary of 5000 most frequent words in each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating P(W|C) for each word in each class, by normalizing using Laplace smoothing parameter of 30.\n",
    "\n",
    "Here, CountVectorizer class from scikit-learn has been used to create the Document-Term Matrix. The class has an inbuilt preprocessing module.\n",
    "After calculating the document term matrix, the counts of document in which each word occurs has been calculated to find the most frequent ones for each class. Then, the probability of word given class has been calculated for the top 5000 words. Laplace smoothing parameter of 30 has been used when calculating P(W|C)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to hold vectorizer objects\n",
    "vect_dict = {}\n",
    "# Dictionary to hold Document term matrix for each class.\n",
    "# The document term matrix is converted to a Pandas DataFrame\n",
    "class_dict = {}\n",
    "for label in list(train['label'].unique()):\n",
    "    vect_dict[label] = CountVectorizer(input='filename',analyzer='word',stop_words='english',decode_error='ignore')\n",
    "    class_dict[label] = pd.DataFrame(vect_dict[label].fit_transform(list(train.loc[train['label'] == label]['filename'])).todense().T)\n",
    "    class_dict[label]['count_docs'] = class_dict[label].sum(axis=1)\n",
    "    class_dict[label]['word'] = vect_dict[label].get_feature_names()\n",
    "    class_dict[label] = class_dict[label].sort_values(by='count_docs',ascending=False).iloc[:5000,:]\n",
    "    tot_freq = class_dict[label]['count_docs'].sum() + 30\n",
    "    class_dict[label]['p(w|c)'] =  class_dict[label]['count_docs'] / (tot_freq + (5000 * 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Word Dictionary for each class\n",
    "for label in list(train['label'].unique()):\n",
    "    class_dict[label] = pd.Series(class_dict[label]['p(w|c)'].values,index=class_dict[label]['word']).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_dict['comp.graphics']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words **cmu, edu,com,cs** can be removed for better results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Class Priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_priors_dict = {}\n",
    "total_freq = 0\n",
    "for label in list(files_df['label'].unique()):\n",
    "    class_priors_dict[label] = files_df.loc[files_df['label'] == label].shape[0]\n",
    "    total_freq += class_priors_dict[label]\n",
    "for label in list(files_df['label'].unique()):\n",
    "    class_priors_dict[label] = np.round(class_priors_dict[label] / total_freq, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'comp.graphics': 0.050000000000000003,\n",
       " 'talk.religion.misc': 0.050000000000000003,\n",
       " 'rec.sport.baseball': 0.050000000000000003,\n",
       " 'comp.sys.ibm.pc.hardware': 0.050000000000000003,\n",
       " 'rec.motorcycles': 0.050000000000000003,\n",
       " 'talk.politics.guns': 0.050000000000000003,\n",
       " 'misc.forsale': 0.050000000000000003,\n",
       " 'alt.atheism': 0.050000000000000003,\n",
       " 'talk.politics.misc': 0.050000000000000003,\n",
       " 'talk.politics.mideast': 0.050000000000000003,\n",
       " 'rec.autos': 0.050000000000000003,\n",
       " 'comp.windows.x': 0.050000000000000003,\n",
       " 'sci.crypt': 0.050000000000000003,\n",
       " 'sci.electronics': 0.050000000000000003,\n",
       " 'soc.religion.christian': 0.0499,\n",
       " 'rec.sport.hockey': 0.050000000000000003,\n",
       " 'comp.os.ms-windows.misc': 0.050000000000000003,\n",
       " 'sci.space': 0.050000000000000003,\n",
       " 'comp.sys.mac.hardware': 0.050000000000000003,\n",
       " 'sci.med': 0.050000000000000003}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_priors_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    stemmer = LancasterStemmer()\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "def normalize(words):\n",
    "    words = remove_non_ascii(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    #words = lemmatize_verbs(words)\n",
    "    #words = stem_words(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words = []\n",
    "for train_doc in train['filename']:\n",
    "    with open(train_doc,'r',errors='ignore') as filein:\n",
    "        words = nltk.word_tokenize(filein.read())\n",
    "        words = normalize(words)\n",
    "        train_words.append(words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predicted = pd.DataFrame(columns=['predicted','max_class_posterior_prob'])\n",
    "for train_words_list in train_words:\n",
    "    log_posterior_dict = class_priors_dict\n",
    "    log_posterior_dict = dict([(k,math.log(v)) for (k,v) in log_posterior_dict.items()])\n",
    "    for word in train_words_list:\n",
    "        for k,v in log_posterior_dict.items():\n",
    "            try:\n",
    "                log_posterior_dict[k] = log_posterior_dict[k] + math.log(class_dict[k][word])\n",
    "            except:\n",
    "                pass\n",
    "    log_posterior_dict = dict([(k,np.exp(v)) for (k,v) in log_posterior_dict.items()])\n",
    "    train_predicted = train_predicted.append({'predicted':max(log_posterior_dict, key=log_posterior_dict.get),'max_class_posterior_prob':max(log_posterior_dict.values())},ignore_index=True)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>max_class_posterior_prob</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>talk.politics.mideast</td>\n",
       "      <td>1.110726e-130</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>1.571055e-113</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>talk.politics.mideast</td>\n",
       "      <td>5.849009e-158</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>5.692217e-113</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>7.939355e-142</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               predicted  max_class_posterior_prob         actual\n",
       "0  talk.politics.mideast             1.110726e-130  comp.graphics\n",
       "1     rec.sport.baseball             1.571055e-113  comp.graphics\n",
       "2  talk.politics.mideast             5.849009e-158  comp.graphics\n",
       "3     rec.sport.baseball             5.692217e-113  comp.graphics\n",
       "4     rec.sport.baseball             7.939355e-142  comp.graphics"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predicted['actual'] = train['label']\n",
    "train_predicted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 3)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predicted.loc[train_predicted['predicted'] == train_predicted['actual']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13997, 3)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy : 0.005786954347360149\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy : {}'.format(train_predicted.loc[train_predicted['predicted'] == train_predicted['actual']].shape[0]/train_predicted.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words = []\n",
    "for test_doc in test['filename']:\n",
    "    with open(test_doc,'r',errors='ignore') as filein:\n",
    "        words = nltk.word_tokenize(filein.read())\n",
    "        words = normalize(words)\n",
    "        test_words.append(words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicted = pd.DataFrame(columns=['predicted','max_class_posterior_prob'])\n",
    "for test_words_list in test_words:\n",
    "    log_posterior_dict = class_priors_dict\n",
    "    log_posterior_dict = dict([(k,math.log(v)) for (k,v) in log_posterior_dict.items()])\n",
    "    for word in test_words_list:\n",
    "        for k,v in log_posterior_dict.items():\n",
    "            try:\n",
    "                log_posterior_dict[k] = log_posterior_dict[k] + math.log(class_dict[k][word])\n",
    "            except:\n",
    "                pass\n",
    "    log_posterior_dict = dict([(k,np.exp(v)) for (k,v) in log_posterior_dict.items()])\n",
    "    test_predicted = test_predicted.append({'predicted':max(log_posterior_dict, key=log_posterior_dict.get),'max_class_posterior_prob':max(log_posterior_dict.values())},ignore_index=True)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>max_class_posterior_prob</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>2.077055e-199</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>2.388091e-178</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>8.528300e-157</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>1.434837e-297</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted  max_class_posterior_prob         actual\n",
       "0  rec.sport.baseball             2.077055e-199  comp.graphics\n",
       "1    rec.sport.hockey             2.388091e-178  comp.graphics\n",
       "2  rec.sport.baseball             8.528300e-157  comp.graphics\n",
       "3    rec.sport.hockey             1.434837e-297  comp.graphics\n",
       "4       comp.graphics              0.000000e+00  comp.graphics"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predicted['actual'] = test['label']\n",
    "test_predicted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 3)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predicted.loc[test_predicted['predicted'] == test_predicted['actual']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 3)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.007666666666666666\n"
     ]
    }
   ],
   "source": [
    "print('Test Accuracy : {}'.format(test_predicted.loc[test_predicted['predicted'] == test_predicted['actual']].shape[0]/test_predicted.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is seen that the training and test accuracy is very low, at 0.5% and 0.7% respectively. \n",
    "\n",
    "These are the probable reasons for this low accuaracy:\n",
    "* The preprocessing is done differently when training the model and scoring the training and test data\n",
    "* The header information can be removed when training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dictionary of 10,000 most frequent words in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to hold vectorizer objects\n",
    "vect_dict = {}\n",
    "# Dictionary to hold Document term matrix for each class.\n",
    "# The document term matrix is converted to a Pandas DataFrame\n",
    "class_dict = {}\n",
    "for label in list(train['label'].unique()):\n",
    "    vect_dict[label] = CountVectorizer(input='filename',analyzer='word',stop_words='english',decode_error='ignore')\n",
    "    class_dict[label] = pd.DataFrame(vect_dict[label].fit_transform(list(train.loc[train['label'] == label]['filename'])).todense().T)\n",
    "    class_dict[label]['count_docs'] = class_dict[label].sum(axis=1)\n",
    "    class_dict[label]['word'] = vect_dict[label].get_feature_names()\n",
    "    class_dict[label] = class_dict[label].sort_values(by='count_docs',ascending=False).iloc[:10000,:]\n",
    "    tot_freq = class_dict[label]['count_docs'].sum() + 30\n",
    "    class_dict[label]['p(w|c)'] =  class_dict[label]['count_docs'] / (tot_freq + (10000 * 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Word Dictionary for each class\n",
    "for label in list(train['label'].unique()):\n",
    "    class_dict[label] = pd.Series(class_dict[label]['p(w|c)'].values,index=class_dict[label]['word']).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predicted = pd.DataFrame(columns=['predicted','max_class_posterior_prob'])\n",
    "for train_words_list in train_words:\n",
    "    log_posterior_dict = class_priors_dict\n",
    "    log_posterior_dict = dict([(k,math.log(v)) for (k,v) in log_posterior_dict.items()])\n",
    "    for word in train_words_list:\n",
    "        for k,v in log_posterior_dict.items():\n",
    "            try:\n",
    "                log_posterior_dict[k] = log_posterior_dict[k] + math.log(class_dict[k][word])\n",
    "            except:\n",
    "                pass\n",
    "    log_posterior_dict = dict([(k,np.exp(v)) for (k,v) in log_posterior_dict.items()])\n",
    "    train_predicted = train_predicted.append({'predicted':max(log_posterior_dict, key=log_posterior_dict.get),'max_class_posterior_prob':max(log_posterior_dict.values())},ignore_index=True)\n",
    "    \n",
    "train_predicted['actual'] = train['label']      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy : 0.010573694363077802\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy : {}'.format(train_predicted.loc[train_predicted['predicted'] == train_predicted['actual']].shape[0]/train_predicted.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicted = pd.DataFrame(columns=['predicted','max_class_posterior_prob'])\n",
    "for test_words_list in test_words:\n",
    "    log_posterior_dict = class_priors_dict\n",
    "    log_posterior_dict = dict([(k,math.log(v)) for (k,v) in log_posterior_dict.items()])\n",
    "    for word in test_words_list:\n",
    "        for k,v in log_posterior_dict.items():\n",
    "            try:\n",
    "                log_posterior_dict[k] = log_posterior_dict[k] + math.log(class_dict[k][word])\n",
    "            except:\n",
    "                pass\n",
    "    log_posterior_dict = dict([(k,np.exp(v)) for (k,v) in log_posterior_dict.items()])\n",
    "    test_predicted = test_predicted.append({'predicted':max(log_posterior_dict, key=log_posterior_dict.get),'max_class_posterior_prob':max(log_posterior_dict.values())},ignore_index=True)\n",
    "    \n",
    "test_predicted['actual'] = test['label']       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.011833333333333333\n"
     ]
    }
   ],
   "source": [
    "print('Test Accuracy : {}'.format(test_predicted.loc[test_predicted['predicted'] == test_predicted['actual']].shape[0]/test_predicted.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It is seen that increasing the dictionary to 10,000 increases the training and test accuracies to 1%. This can be improved further.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
